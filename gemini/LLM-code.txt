
import pandas as pd
import numpy as np
import networkx as nx
import torch
from torch_geometric.data import Data
from torch_geometric.nn import GCNConv
from torch_geometric.utils import from_networkx
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score
from sklearn.preprocessing import OneHotEncoder
import torch.nn.functional as F
import torch.optim as optim

# Load connection data
connections = pd.read_csv('data/flywire/connections.csv')

# Filter connections for LH_L neuropil
lh_l_connections = connections[connections['neuropil'] == 'LH_L']

# Create a graph from the connection data
graph = nx.from_pandas_edgelist(lh_l_connections, 'pre_root_id', 'post_root_id', edge_attr='syn_count')

# Load neuron data (replace with your actual loading function)
# This is a placeholder, replace with your actual neuron data loading
neurons = pd.DataFrame({'root_id': list(graph.nodes), 'cell_type': ['typeA'] * len(graph.nodes)})

# One-hot encode cell types
enc = OneHotEncoder(handle_unknown='ignore')
node_attributes = enc.fit_transform(neurons[['cell_type']]).toarray()

# Convert NetworkX graph to PyG Data object
data = from_networkx(graph)

# Add node and edge features
data.x = torch.tensor(node_attributes, dtype=torch.float)
data.edge_attr = torch.tensor(np.array(list(nx.get_edge_attributes(graph, 'syn_count').values())).reshape(-1,1), dtype=torch.float)

# Create train/test split for edges
edge_index = data.edge_index
edge_label = torch.randint(0, 2,(data.num_edges,)).float() #generate random edge labels for demonstration
train_edge_index, test_edge_index, train_edge_label, test_edge_label = train_test_split(edge_index.T, edge_label, test_size=0.2, random_state=42)

train_edge_index = torch.tensor(train_edge_index).T
test_edge_index = torch.tensor(test_edge_index).T
train_edge_label = torch.tensor(train_edge_label)
test_edge_label = torch.tensor(test_edge_label)


# Define the GNN model
class GNN(torch.nn.Module):
    def __init__(self, in_channels, hidden_channels, out_channels):
        super().__init__()
        self.conv1 = GCNConv(in_channels, hidden_channels)
        self.conv2 = GCNConv(hidden_channels, out_channels)

    def forward(self, x, edge_index):
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = F.dropout(x, training=self.training)
        x = self.conv2(x, edge_index)
        return torch.sigmoid(x)

# Initialize model, optimizer, and loss function
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = GNN(node_attributes.shape[1], 64, 1).to(device)
optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)
criterion = torch.nn.BCELoss()

# Training loop
epochs = 100
results = []
for epoch in range(epochs):
    model.train()
    optimizer.zero_grad()
    node_embeddings = model(data.x.to(device), data.edge_index.to(device))
    source_nodes = node_embeddings[train_edge_index[0,:]]
    target_nodes = node_embeddings[train_edge_index[1,:]]
    combined_embeddings = torch.cat((source_nodes,target_nodes),dim=1)
    linear_layer = torch.nn.Linear(combined_embeddings.shape[1],1)
    out = linear_layer(combined_embeddings)
    out = torch.clamp(out, 1e-7, 1-1e-7) #clamp to avoid log(0) and log(1) errors in BCELoss
    loss = criterion(out.squeeze(), train_edge_label.to(device))
    loss.backward()
    optimizer.step()

    model.eval()
    with torch.no_grad():
        node_embeddings_test = model(data.x.to(device), data.edge_index.to(device))
        source_nodes_test = node_embeddings_test[test_edge_index[0,:]]
        target_nodes_test = node_embeddings_test[test_edge_index[1,:]]
        combined_embeddings_test = torch.cat((source_nodes_test,target_nodes_test),dim=1)
        out_test = linear_layer(combined_embeddings_test)
        out_test = torch.clamp(out_test, 1e-7, 1-1e-7) #clamp to avoid log(0) and log(1) errors in BCELoss
        auc = roc_auc_score(test_edge_label.cpu().numpy(), out_test.cpu().numpy())
        results.append([epoch, loss.item(), auc])
    print(f'Epoch: {epoch+1}, Loss: {loss.item():.4f}, Test AUC: {auc:.4f}')

# Save the model
torch.save(model.state_dict(), 'trained-GNN.pt')

# Save the results
pd.DataFrame(results, columns=['Epoch', 'Loss', 'AUC']).to_csv('results.csv', index=False)
